{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file calculates metrics for maps on the full reconstruction and temporal deconstructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# For accessing directories\n",
    "# =========================================\n",
    "root_dir = \"/local/data/artemis/workspace/jfs2167/recon_eval\" # Set this to the path of the project\n",
    "\n",
    "reference_output_dir = f\"{root_dir}/references\"\n",
    "recon_output_dir = f\"{root_dir}/models/reconstructions\"\n",
    "other_output_dir = f\"{root_dir}/models/performance_metrics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading references\n",
    "path_LET = f\"{reference_output_dir}/members_LET_dict.pickle\"\n",
    "\n",
    "with open(path_LET,'rb') as handle:\n",
    "    mems_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# List of approaches\n",
    "# =========================================\n",
    "approaches = [\"rf\", \"xg\", \"nn\"]\n",
    "\n",
    "# =========================================\n",
    "# NN reference for selecting correct run to use\n",
    "# =========================================\n",
    "val_df_fname = f\"{other_output_dir}/nn/nn_test_performance_df.pickle\"\n",
    "nn_val_df = pd.read_pickle(val_df_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full reconstruction and temporal deconstruction metric maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [\"raw\", \"seasonal\", \"decadal\", \"resid\"]\n",
    "\n",
    "map_data = defaultdict(float) # Data by ML approach\n",
    "map_data_ens = defaultdict(float) # Data by ML approach and ensemble model\n",
    "\n",
    "N_ens = 25\n",
    "N_tot = 100\n",
    "\n",
    "for ens, mem_list in mems_dict.items():\n",
    "    print(ens)\n",
    "    for member in mem_list:\n",
    "        print(member)\n",
    "        for approach in approaches:\n",
    "            recon_dir = f\"{recon_output_dir}/{approach}/{ens}/member_{member}\"\n",
    "            \n",
    "            if approach == \"nn\":\n",
    "                run = nn_val_df.query(\"model == @ens and member == @member and sel_min_bias_mse == 1\").index.values[0][2]\n",
    "                recon_fname_out = f\"{recon_dir}/{approach}_recon_temporal_pC02_2D_mon_{ens}_{member}_{run}_1x1_198201-201701.nc\"\n",
    "            else:\n",
    "                recon_fname_out = f\"{recon_dir}/{approach}_recon_temporal_pC02_2D_mon_{ens}_{member}_1x1_198201-201701.nc\"\n",
    "            \n",
    "            DS_recon = xr.load_dataset(recon_fname_out)\n",
    "            \n",
    "            if approach == \"rf\":\n",
    "                ref = {}\n",
    "                ref[\"raw\"] = DS_recon[\"pCO2\"]\n",
    "                for i in data_types[1:]:\n",
    "                    ref[i] = DS_recon[f\"pCO2_{i}\"]\n",
    "            \n",
    "            recon = {}\n",
    "            recon[\"raw\"] = DS_recon[\"pCO2_recon\"]\n",
    "            for i in data_types[1:]:\n",
    "                recon[i] = DS_recon[f\"pCO2_recon_{i}\"]\n",
    "                \n",
    "            for i in data_types:\n",
    "                xmean = ref[i].mean(\"time\")\n",
    "                ymean = recon[i].mean(\"time\")\n",
    "                x_minus_mean = ref[i] - xmean\n",
    "                y_minus_mean = recon[i] - ymean\n",
    "                ssx = xr.ufuncs.sqrt((x_minus_mean**2).sum(\"time\"))\n",
    "                ssy = xr.ufuncs.sqrt((y_minus_mean**2).sum(\"time\"))\n",
    "                \n",
    "                corr = ( x_minus_mean * y_minus_mean ).sum(\"time\") / (ssx*ssy)\n",
    "                std_x = ref[i].std(\"time\")\n",
    "                std_y = recon[i].std(\"time\")\n",
    "                bias = (ymean - xmean)\n",
    "                \n",
    "                # Average bias\n",
    "                map_data[(approach,i,\"bias_mean\")] += bias / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"bias_mean\")] += bias / N_ens\n",
    "                \n",
    "                # Average bias**2\n",
    "                map_data[(approach,i,\"bias_sq\")] += bias**2 / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"bias_sq\")] += bias**2 / N_ens\n",
    "                \n",
    "                # Max bias\n",
    "                map_data[(approach,i,\"bias_max\")] = np.maximum(map_data[(approach,i,\"bias_max\")], bias)\n",
    "                map_data_ens[(ens,approach,i,\"bias_max\")] = np.maximum(map_data_ens[(ens,approach,i,\"bias_max\")], bias)\n",
    "                \n",
    "                # Min bias\n",
    "                map_data[(approach,i,\"bias_min\")] = np.minimum(map_data[(approach,i,\"bias_min\")], bias)\n",
    "                map_data_ens[(ens,approach,i,\"bias_min\")] = np.minimum(map_data_ens[(ens,approach,i,\"bias_min\")], bias)\n",
    "                \n",
    "                # Mean absolute error\n",
    "                map_data[(approach,i,\"mae\")] += np.abs(bias) / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"mae\")] += np.abs(bias) / N_ens\n",
    "                \n",
    "                # Mean % bias\n",
    "                map_data[(approach,i,\"bias_%error\")] += bias/xmean / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"bias_%error\")] += bias/xmean / N_ens\n",
    "                \n",
    "                # Mean absolute % bias\n",
    "                map_data[(approach,i,\"mae_%error\")] += np.abs(bias)/xmean / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"mae_%error\")] += np.abs(bias)/xmean / N_ens\n",
    "                \n",
    "                # Mean correlation\n",
    "                map_data[(approach,i,\"corr_mean\")] += corr / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"corr_mean\")] += corr / N_ens\n",
    "                \n",
    "                # Average corr**2\n",
    "                map_data[(approach,i,\"corr_sq\")] += corr**2 / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"corr_sq\")] += corr**2 / N_ens\n",
    "\n",
    "                # Stdev (amplitude) percentage error\n",
    "                map_data[(approach,i,\"amp_%error\")] += (std_y-std_x)/std_x / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"amp_%error\")] += (std_y-std_x)/std_x / N_ens\n",
    "\n",
    "                # Stdev (amplitude) absolute percentage error           \n",
    "                map_data[(approach,i,\"stdev_%error\")] += np.abs(std_y-std_x)/std_x / N_tot\n",
    "                map_data_ens[(ens,approach,i,\"stdev_%error\")] += np.abs(std_y-std_x)/std_x / N_ens\n",
    "\n",
    "                \n",
    "for approach in approaches:\n",
    "    for i in data_types:\n",
    "        map_data[(approach,i,\"bias_std\")] = np.sqrt(map_data[(approach,i,\"bias_sq\")] - map_data[(approach,i,\"bias_mean\")]**2)\n",
    "        map_data[(approach,i,\"corr_std\")] = np.sqrt(map_data[(approach,i,\"corr_sq\")] - map_data[(approach,i,\"corr_mean\")]**2)\n",
    "\n",
    "        for ens in mems_dict.keys():\n",
    "            map_data_ens[(ens,approach,i,\"bias_std\")] = np.sqrt(map_data_ens[(ens,approach,i,\"bias_sq\")] - map_data_ens[(ens,approach,i,\"bias_mean\")]**2)\n",
    "            map_data_ens[(ens,approach,i,\"corr_std\")] = np.sqrt(map_data_ens[(ens,approach,i,\"corr_sq\")] - map_data_ens[(ens,approach,i,\"corr_mean\")]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data_fname = f\"{other_output_dir}/map_data_approach.pickle\"\n",
    "map_data_ens_fname = f\"{other_output_dir}/map_data_ens.pickle\"\n",
    "\n",
    "with open(map_data_fname,\"wb\") as handle:\n",
    "    pickle.dump(map_data, handle)\n",
    "\n",
    "with open(map_data_ens_fname,\"wb\") as handle:\n",
    "    pickle.dump(map_data_ens, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (jfs_devd)",
   "language": "python",
   "name": "jfs_devd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
