{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes the raw xarray files (which can be found at https://figshare.com/collections/Large_ensemble_pCO2_testbed/4568555), applies feature transformations, and saves it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# For accessing directories\n",
    "# =========================================\n",
    "root_dir = \"/local/data/artemis/workspace/jfs2167/recon_eval\" # Set this to the path of the project\n",
    "ensemble_dir_head = \"/local/data/artemis/simulations/LET\" # Set this to where you have placed the raw data\n",
    "\n",
    "data_output_dir = f\"{root_dir}/data/processed\"\n",
    "reference_output_dir = f\"{root_dir}/references\"\n",
    "xco2_path = f\"{ensemble_dir_head}/CESM/member_001/XCO2_1D_mon_CESM001_native_198201-201701.nc\" # Forcing is the same across members so only reference it once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# standard imports\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Python file with supporting functions\n",
    "import pre "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading references\n",
    "path_LET = f\"{reference_output_dir}/members_LET_dict.pickle\"\n",
    "path_seeds = f\"{reference_output_dir}/random_seeds.npy\"\n",
    "path_loc = f\"{reference_output_dir}/members_seed_loc_dict.pickle\"\n",
    "with open(path_LET,'rb') as handle:\n",
    "    mems_dict = pickle.load(handle)\n",
    "    \n",
    "random_seeds = np.load(path_seeds)    \n",
    "    \n",
    "with open(path_loc,'rb') as handle:\n",
    "    seed_loc_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Setting the date range to unify the date type\n",
    "# =========================================\n",
    "\n",
    "# Define date range\n",
    "date_range_start = '1982-01-01T00:00:00.000000000'\n",
    "date_range_end = '2017-01-31T00:00:00.000000000'\n",
    "\n",
    "# create date vector\n",
    "dates = pd.date_range(start=date_range_start, \n",
    "                      end=date_range_end,freq='MS') + np.timedelta64(14, 'D')\n",
    "\n",
    "# Select the start and end\n",
    "date_start = dates[0]\n",
    "date_end = dates[420]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop to load in data, clean it, and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_list = ['CanESM2', 'CESM', 'GFDL', 'MPI']\n",
    "ensemble_list = []\n",
    "\n",
    "for ens, mem_list in mems_dict.items():\n",
    "    for member in mem_list:\n",
    "        # This function loads in the data, cleans it, and creates a pandas data frame\n",
    "        df = pre.create_inputs(ensemble_dir_head, ens, member, dates, xco2_path=xco2_path)\n",
    "        \n",
    "        # Save the pandas data frame to my workspace\n",
    "        pre.save_clean_data(df, data_output_dir, ens, member)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (jfs_devd)",
   "language": "python",
   "name": "jfs_devd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
